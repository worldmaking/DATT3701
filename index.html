<!doctype html>
<html>
<head>
<meta charset="utf-8"/>
<title>DATT3701</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="css/normalize.css">
<link rel="stylesheet" href="css/skeleton.css">
<style>
/* see https://getskeleton.com/ */
/* html { font-size: 100%; } */
table { width:100%; }
img { width: 100%; max-width: 100%; }
.youtube {
 	max-width: 640px;
    overflow: hidden;
}
.youtube img {
    max-width: 320px;
}
</style>
</head>
<body>
<div class="container">
<div class="row">
<div class="full column">
<h1>FA/DATT 3701 6.00 Collaborative Game Project</h1>
<div id="toc"></div>
</div>
</div>
<div class="row">
<div class="full column" id="main_body">
<script type="bogus" id="sourcetext">


## Course Description

In this year long studio course the class collaborates on the realization of two or three ambitious game projects. Students will work together as a development team by taking on roles where they focus on specific aspects of the project (such as Director, Designer, Artist, Programmer, Level Designer, Sound Designer, Publicity, etc.) The development team structure is modeled on teams used in large-scale project development within fields related to games that rely on multi-stakeholder collaboration and interdisciplinary research. Projects may incorporate partnerships with York-based or external Faculties, Departments, or research teams depending on the focus of the project. The nature of the project themes will vary from year to year, but will be a significant work in the field of games. 

The course instructor(s) will prepare a general description of the project(s) at the beginning of the course. The details of the project(s) will be developed as part of the class activities. As part of the project development and execution students will be expected to prepare presentations, posters, and a written paper. The culmination of this course will be a final presentation in a public venue. In addition to group assignments, students are evaluated based on their individual contribution, teamwork, presentations, and other deliverables as appropriate. 

**Prerequisites:** Only open to students the Digital Media Specialized Honours BA program Games stream. FA/DATT 2300 3.0, FA/DATT 2301 3.0, LE/EECS 2030 3.0 Course credit exclusion: FA/DATT 3700 6.0

**Instructors:** Yifat Shaik & Graham Wakefield

**Time:** Mondays, 1.30pm - 4.30pm

**Location:** ACW 103

Additional resource locations:
- [The Digital Media Art & Technology Learning Lab (ATLL), Accolade West 102](https://dm.ampd.yorku.ca). To use the Digital Media Lab outside of class time, you must purchase a Digital Media Lab Card. Lab Cards are $25 for the year, or $15 for one term. The Digital Media Lab Card can be purchased in the front desk of the Computational Arts/Visual Arts and Art History office, located on the second floor of the Goldfarb Centre for Fine Arts. The office is open Monday to Friday, 8:30am-4:30pm. Once you have paid, take your receipt to Frank Tsonis in ACW 102 and he will issue you a card.
- [Alice lab, GCFA309](https://worldmaking.github.io), with VR and motion tracking systems. 
- AMPD's Motion Media Lab at [Cinespace Film Studios](https://cinespace.com), with an [Organic Motion markerless motion capture](https://www.organicmotion.com). 

**Language of Instruction:** English

## Organization of the Course 

The first part of the course focuses on ideation toward proposal development, including rapid pitching, peer reviews, thematic lectures, tutorials, individual research and experimentation, establishing groups, critique and discussion, collaborative sketching, design document development, project management, alpha development, and internal and external review. We expect to approve two or three projects for production, by groups of between three and six members each. 

The second part of the course focuses on production, culminating in public dissemination, with team members taking on specific roles and responsibilities, supported by periodic demo and test, critique/review, and specialized technical tutorials. The final game must be presented in at least one public event prior to the end of the semester. 

Beside group work, throughout the course you will be asked to maintain a 'devblog' updated weekly, to submit a number of individual written assignments or questionnaires, and contribute generously to in-class discussions. Students must attend all class times, and should expect to spend an average of two to three hours per week on assignments and contributions to group work outside of class time.

Throughout the course, as instructors we will act primarily in two roles. First, we will act as the clients, perhaps akin to publishers or curators, of the projects: we issue the call, we articulate the requirements, and will play the principal role in selecting and refining the proposals and their subsequent production. Second, we will act as pedagogical and technical support: we will lead several guided tutorial sessions in the likely software platforms for projects, followed by focused lab guidance as the projects develop.

## Evaluation

The final grade for the course will be based on the following items weighted as indicated:

**Fall Semester**
- Short written assignments: 20% 
- Group proposals: 20% 
- Group prototypes & presentations: 40% 
- Role contribution: 20%

**Winter Semester**
- Role contribution: 30% 
- Reflective papers: 30% 
- Final project: 40%

**Grading**: The final grade is derived from the mean of the Fall and Winter grades. The grading scheme for the course conforms to the 9-point grading system used in undergraduate programs at York (e.g., A+ = 9, A = 8, B+ - 7, C+ = 5, etc.). Assignments and tests will bear either a letter grade designation or a corresponding number grade (e.g., A+ = 90 to 100, A = 80 to 90, B+ = 75 to 79, etc.)  For a full description of York grading system see the York University Undergraduate Calendar at [https://calendars.registrar.yorku.ca/2010-2011/academic/index.htm](https://calendars.registrar.yorku.ca/2010-2011/academic/index.htm).
**Assignment Submission:** Proper academic performance depends on students doing their work not only well, but on time. Accordingly, assignments for this course must be received on the due date specified for the assignment. ***All assignments must be submitted to complete the course.***

**Lateness Penalty:** Assignments received later than the due date will be penalized five grade points per day that assignment is late. Exceptions to the lateness penalty for valid reasons such as illness, compassionate grounds, etc., may be entertained by the Course Instructor but will require supporting documentation (e.g., a doctor’s letter).

-----

## Schedule

This schedule will be continually updated.

### Fall semester

**Week 1 (Sep 11):**

- Overview of course, procedures, content

- Introductions

- The call for submissions
	- Rationale
	- Examples 
	- Discussion
	
![What is a game?](img/sep11.jpg)

- Task 1: prepare a 4-minute "elevator pitch"
	- An Elevator Pitch is a summary used to quickly and simply define your idea, and its *value proposition.*
	- Your pitch should be concise but compelling
	- Focus on what is **unique** about your idea, how it differentiates itself
	- Contextualize your idea with reference to other work (not necessarily games). 
	- You will only be able to use the classroom computer's web browser to support your pitch.
	- We will maintain the 5 minutes ruthlessly. You must fill all of the time, and no more. 
	- If you had several ideas or variants tell us, but first focus should be on the one you think is most interesting in how it responds to the call
	
**Week 2 (Sep 18):** 

- 4 minute elevator pitches

**Week 3 (Sep 25):** 
 
- Pitches feedback, groupings
- Introduction to VR
 
**Week 4 (Oct 2):** 

Oct 9: University closed

*(Oct 6-8: [IndieCade LA](https://www.indiecade.com/))*

**Week 5 (Oct 16):** 

**Week 6 (Oct 23):** 

<!--Due: Design document-->

**Week 7 (Oct 30):** 

**Week 8 (Nov 6):** 

<!--Internal review-->

**Week 9 (Nov 13):** 

**Week 10 (Nov 20):** 

**Week 11 (Nov 27):** 

**Week 12 (Dec 4):** 

Presentation & demo to external reviewers

### Winter semester

**Week 13 (Jan 8):**

**Week 14 (Jan 15):** 

**Week 15 (Jan 22):** 

*(Jan 26-28: [Global Game Jam](https://globalgamejam.org/news/announcing-new-executive-producer-and-committee-2018))*
 
**Week 16 (Jan 29):** 

**Week 17 (Feb 5):** 

**Week 18 (Feb 12):** 

Feb 19: University closed

**Week 19 (Feb 26):** 

**Week 20 (Mar 5):** 

**Week 21 (Mar 12):** 

**Week 22 (Mar 19):** 

*([GDC 2018](https://www.gdconf.com) & [IGF 2018](https://www.igf.com), San Francisco)*

*([SXSW Gaming 2018](https://gaming.sxsw.com/expo/indie-corner/), Austin)*

**Week 23 (Mar 26):** 

Final documentation

**Week 24 (Apr 2):** 

Post-mortem

*(Apr 5: [LevelUp Showcase](levelupshowcase.com), Toronto)*

*(July: [Games for Change](https://www.gamesforchange.org) Festival, NY)*

---

## The call for work

We seek proposals for three new works in the area of computer video games, to be developed to a fully-realized play-tested state suitable for its presentation in a public venue, and dissemination online.

The first requirement: We are specifically seeking works that break central conventions of gaming, or address a paradoxical character of gaming media, in a clearly articulated way. 

The second requiremnt: Each project should further differentiate itself by integrate its theme centrally with at least one non-conventional or newly emerging interface format:

- Alternative controllers (alt.ctrl) including physical computing
- Virtual Reality Head-Mounted Display (probably limited to one team only)
- Augmented / Mixed Reality
- Some other alternative interface format, e.g. audio-driven gaming 

We will introduce and are happy to support mainstream gaming engines including Unreal and Unity, as well as less conventional platforms such as Max/MSP/Jitter, Cinder, JS/WebGL, Processing, Arduino, etc. 

## Rationale for the call

First: The computer/video games industry (AKA interactive entertainment industry) is 45 years old, and stratified. Many problems, crises. For example:

- **781 million** games on Steam
	- 37% of these have never been played
	- Nearly 40% uploaded in the last year
	- Steam abandoned control (Greenlight), replaced with curating program, but already curators of curators...
	- Vast majority are copycats, cheap spinoffs, generic and formulaic stereotypes
	- Investors averse to risky concepts with big budgets; low price points require quick turnaround; both lead to least common denominator
	- Also much easier to generate minor variants of a formula or template than to be genuinely original.

Nobody wants to see a portfolio of mediocrity. Away from the mainstream, there are more experimental corners of independent (and occasionally corporate) games demonstrating many refreshingly unusual approaches. Some of these have become so successful that they have launched entire new genres. Even those that don't attract a lot of attention. The most interesting innovators and movements in art (and elsewhere) are born from rejecting tradition.

Second: the experiences that work well on standard gaming platforms do not always translate well to alternate platforms and interfaces. What makes a new interface or format most interesting may also be how it confounds conventional gaming tropes. Like any new format, it is well worth stepping back from the contemporary world to see bigger pictures. What is the real message of the medium? What can it say that hasn't been said? 

But to stretch expectations or break conventions, we need to identify what they are. So perhaps to begin, ***what exactly is a game?***

<!--
In [Reality is Broken](https://janemcgonigal.com/my-book/) Jane McGonigal identifies  four defining traits within the vast diversity of games (both within & beyond the digital forms). Everything else McGonigal holds are there to enhance these four traits, including immersive graphics, that increase our ability to pay sustained attention:

- **goal(s):** outcomes to achieve, focusing attention and orienting partipation. Purpose.
- **rules:** limitations on how goals can be achieved. "Rules push players to explore previously uncharted possibility spaces. They unleash creativity and foster strategic thinking."
- **feedback system:** Tells players how close they are to achieving goals. Points, levels, scores, progress bars, "the game is over when...", etc. A promise of achievability, and a motivation to continue playing. Variety and intensity of feedback is what differentiates digital and non-digital games. You can feel how attentive the game is to you, and approach the very limits of flow).
- **voluntary participation:** All players knowingly and willingly accept the goal, rules, and feedback. A common ground for participation. Freedom to enter/leave establishes a safe and pleasurable activity.

Bernard Suits sums it up: **"Playing a game is the voluntary attempt to overcome unnecessary obstacles."**, which McGonigal paraphrases: "any well-designed game is an invitation to tackle an unnecessary obstacle". "Freedom to work in the most logical and efficient way is the very opposite of gameplay." For example, golf: choosing to make the work of getting a ball into a hole more difficult. Or Portal: the goal at first is to figure out what the goal is; like many games, some puzzles teach you a new capability (new rules).

Why do unnecessary obstacles make us happy? Hard work that we **choose** to do, with no real danger. The opposite of play isn't work, it's depression: pessimistic sense of inadequacy, despondent lack of activity, being forced into the wrong place. Gameplay gives an optimistic sense of capabilities, invigorating rush of activity, positive valence. Fiero: possibly the most primal emotional rush we can experience. Italian for pride, triumph over adversity. Play activates all neurological/physiological systems of happiness: attention systems, reward center, motivation systems, emotion & memory centers... in a way that passive low-engagement activities (tv, chocolate, window-shopping etc.) don't. Tal Ben-Shahar: **"we're much happier enlivening time rather than killing time."**

## Manifesto for a ludic century (Erik Zimmerman)

Erik Zimmerman's article [on Kotaku](https://kotaku.com/manifesto-the-21st-century-will-be-defined-by-games-1275355204), formed as a manifesto, argues for games as the defining medium of the current century:

> The last century's media was based on information communication: linear, often unidirectional; creating bureaucratic systems. This century's media is non-linear, systemic, modular, participatory, customizable, playful. Environmental: immersive, inhabitable, explorable. Complex systems thinking. 

> It is not enough to merely be a systems-literate person; to understand systems in an analytic sense. We also must learn to be playful in them. A playful system is a human system, a social system rife with contradictions and with possibility.

Ian Bogost's response: [Winning Isn't Everything](https://medium.com/matter/winning-isnt-everything-255b3a26d1cf):

>  "I used to think that games would be the dominant medium of the 21st century. The reality? They're too big, too complex, and too smart for that to be true."

## What is a notgame|nongame|ungame|anti-game?

> "One obvious difference between art and games is that you can win a game. It has rules, points, objectives, and an outcome. Santiago might cite an immersive game without points or rules, but I would say then it ceases to be a game and becomes a representation of a story, a novel, a play, dance, a film. Those are things you cannot win; you can only experience them." [Roger Ebert, "Video games can never be art"](https://www.rogerebert.com/rogers-journal/video-games-can-never-be-art). *(Ebert later conceded that games may indeed be art in a non-traditional sense.)*

Tetris is one of the most famous and addictive games, but it is one that can't be won. Competition and winning are *not* defining features of games. 

[notgames.org](https://notgames.org) - "Can we create a form of digital entertainment that explicitly rejects the structure of games? ... that does not rely on competition, goals, rewards, winning or losing?"

> "a form of entertainment that really doesn't have a winner, or even a real conclusion" - Nintendo president Satoru Iwata ([wikipedia](https://en.wikipedia.org/wiki/Non-game))

Non-games have existed since the early days of video games, although there hasn't been a specific term for them. The most famous large-scale industry examples are SimCity and Second Life, but recently there has been a lot more active creativity outside the normal bounds of gaming, especially coming from the indie community, and more widely considered close to [games-as-art](https://en.wikipedia.org/wiki/Video_games_as_an_art_form). In the last couple of years, some have been called "walking simulators" -- although this doesn't capture the full range of experiences found, the rejection of common tropes and trend toward purposelessness is evident. 

> Now that there's so much willingness, technology and skill to create beautiful virtual worlds, it's disappointing how many videogames cling to obstacle-based designs. As if players have to earn the privilege to explore by passing an irrelevant test. Now is the time to open up this medium, to let go of our affections and addictions, of our loyalty to childhood memories, to open up the beauty of videogames for the world to see... Let design mean the building of bridges and the opening of doors, not the hiding of keys and the cowardly sniper shot. (Michael Samyn, TaleOfTales)

Inevitably, here's another manifesto: [Michael Samyn. Not a Manifesto](https://notgames.org/blog/2010/03/19/not-a-manifesto/)

Related to [infinite games](https://en.wikipedia.org/wiki/Finite_and_Infinite_Games).

A recommended [notgames Tumblr](https://notgames.tumblr.com).

[Notgames festival](https://notgames.colognegamelab.com/exhibition.html), since 2011. The [keynote presentation](https://notgames.org/blog/2011/08/23/notgames-fest-keynote/) for the first.




 It could be different games, non-games, not-games, glitch games, non-standard gameplays, non-standard interfaces, games as art -->

## Reference points:

### Proteus

<div class="youtube" data-embed="gWs_RKXkyu0"></div>

[Proteus](https://www.visitproteus.com) is an "open world exploration game". **It has no specific goals.** Every creature and plant has a unique musical signature. The game world is procedurally generated, creating a unique layout each game. Non-realistic 8-bit style. Slow-paced.

Proteus sold 23,000 copies in first nine months. It achieved 80% rating on metacritic (despite “not being a game”...)

[wikipedia](https://en.wikipedia.org/wiki/Proteus_(video_game))

### Gardenarium

<div class="youtube" data-embed="c92MWml-Gyo"></div>

### Dear Esther

<div class="youtube" data-embed="hlGdbziSwEY"></div>

Dear Esther is an experimental first-person art video game developed by The Chinese Room. The game does not follow traditional video game conventions, as it involves minimal interaction from the player and does not require choices to be made nor tasks to be completed. It instead places focus on its story, which is told through a fragmented, epistolary narrative as the player explores an unnamed island in the Hebrides.

[On Edge: A Chat With Robert Briscoe](https://www.rockpapershotgun.com/2013/10/23/on-edge-a-chat-with-robert-briscoe/#more-173753) - "One of the goals with Dear Esther's art was to make the island look like one big organic sculpture, with rocks, grass and even buildings seemingly growing from its surface... The caves are a unique break in Dear Esther's bleak, open environments that allowed room to explore a more surreal, organic style that was full of metaphors and hidden imagery... One of my pet gripes is that every game today wants to look like it's shot through Michael Bay's sunglasses or JJ Abrams' asshole"

By October 2013 Dear Esther sold over 750,000 copies.

**Everybody's Gone to the Rapture**

<div class="youtube" data-embed="4Gt_6BHhjaM"></div>

Deep within the Shropshire countryside, the village of Yaughton stands empty. Toys lie forgotten in the playground, the wind blows quarantine leaflets around the silent churchyard. Uncover the traces of the vanished community; discover fragments of events and memories to piece together the mystery of the apocalypse. 

### Flow

<div class="youtube" data-embed="9pRBptP3i1Q"></div>

In the fall of 2005, Jenova Chen and Kellee Santiago began thinking about creating their own video game company. The two were in their final year as master's students in the Interactive Media Program at the University of Southern California's School of Cinematic Arts. 

The title is taken from the eponymous psychological mental state. "In positive psychology, flow, also known as the zone, is the mental state of operation in which a person performing an activity is fully immersed in a feeling of energized focus, full involvement, and enjoyment in the process of the activity." - [Wikipedia](https://en.wikipedia.org/wiki/Flow_(psychology)) Mihály Csíkszentmihályi named this and identified it as a state in which the challenges posed by the environment approach a person's optimal capacity to address them. In the game Flow, one is free to descend or ascend levels of difficulty (as literal levels of depth in the water) to achieve an optimal flow state.

Chen went on to found thatgamecompany and produced works such as Flower and Journey.

**Flower**

<div class="youtube" data-embed="Nnxk-USQyfQ"></div>

In Flower, the player controls the wind, blowing a flower petal through the air using the movement of the game controller. Flying close to flowers results in the player's petal being followed by other flower petals. Flower was primarily intended to arouse positive emotions in the player, rather than to be a challenging and "fun" game. The team viewed their efforts as creating a work of art, removing gameplay elements and mechanics that were not provoking the desired response in the players. 

**Journey**

<div class="youtube" data-embed="i_KrjxD8djo"></div>

In Journey, the player controls a robed figure in a vast desert, traveling towards a mountain in the distance. Other players on the same journey can be discovered, and two players can meet and assist each other, but they cannot communicate via speech or text and cannot see each other's names. The robed figure wears a trailing scarf, which when charged by approaching floating pieces of cloth, briefly allows the player to float through the air. The developers sought to evoke in the player a sense of smallness and wonder, and to forge an emotional connection between them and the anonymous players they meet along the way. - [wiki](https://en.wikipedia.org/wiki/Journey_(2012_video_game))

### The Unfinished Swan

<div class="youtube" data-embed="nhyNzFShhIc"></div>

[The Unfinished Swan](https://www.giantsparrow.com/games/swan/) is a game about exploring the unknown. The player is a young boy chasing after a swan who has wandered off into a surreal, unfinished kingdom. The game begins in a completely white space where players can throw paint to splatter their surroundings and reveal the world around them.

Ian Dallas was also a graduate student at the University of Southern California. "He worked on his idea for a game in a class and periodically went to visit a faculty member, Mark Bolas, to show prototypes. One of those days, he showed off “Whitespace,” where **the idea was to explore a 3D world that started out with a blank screen.** That became the core defining game mechanic behind The Unfinished Swan, which Dallas describes as a “first-person painting” game." [How The Unfinished Swan moved from student project to PS3 downloadable game, by Dean Takahashi](https://venturebeat.com/2013/03/25/how-the-unfinished-swan-moved-from-student-project-to-playstation-3-downloadable-game/)

> In the same article, Dallas also says: “There is a difference between knowing the tools and becoming fluent with them... You want to get under the hood and do things they were not meant to do."

The Unfinished Swan won two BAFTA awards in 2013, one for Game Innovation and one for Debut Game.

More perceptually-challenging explorations:

**Antichamber**

<div class="youtube" data-embed="AnJrz2qNMQw"></div>

A nonlinear, non-euclidean, mondrian-esque FPS. 

**Memory of a Broken Dimension**

<div class="youtube" data-embed="6G_IU5lK1E8"></div>

<div class="youtube" data-embed="ZZgbIJOWbB0"></div>

[https://www.brokendimension.com](https://www.brokendimension.com)

**Naissancee**

<div class="youtube" data-embed="uDSi1-lACNk"></div>

Made with Unreal. Featuring soundtrack composed by Pauline Olivieros, renowned since the 1960's. Inspired by Tsutomu Nihei's famous [Blame!](https://en.wikipedia.org/wiki/Blame!) manga of endless corridors. 

(Another Blame-inspired game that looks interesting [in development here](https://bac9.tumblr.com). Here's [his project blueprint](https://imgur.com/gwdkMgg).)

**Scanner**

<div class="youtube" data-embed="W0uhjXwEQY0"></div>

[Nice feature giving detail on the meshing of technique and story on KillScreen](https://killscreen.com/articles/upcoming-videogame-explore-world-visual-scanner/).

**Devil's Tuning Fork**

<div class="youtube" data-embed="_tKF_subEMA"></div>

A game created by the [DePaul Game Elites team at DePaul University's College of Computing & Digital Media in Chicago.](https://devilstuningfork.com)

### The Stanley Parable

<div class="youtube" data-embed="gblvOhnv2k0"></div>

An interactive fiction video game designed by Davey Wreden. Originally a mod of Half Life 2, it was later rewritten with the Source engine and launched through Steam Greenlight. There are no combat or other action-based sequences. Instead, the player guides Stanley, the game's protagonist, through a surreal environment while the narrator, voiced by British actor Kevan Brighting, delivers exposition. The player has the opportunity to make numerous decisions on which paths to take, and because at times the narrator says what Stanley will do next, the player can choose to ignore the narration and make a different choice. Every choice made by the player is commented on by the narrator, and depending on the choices the player makes, they will encounter different endings to the game before it restarts.

**The Beginner's Guide**

<div class="youtube" data-embed="OPP9pdApRQE"></div>

Narrated by Davey Wreden, it takes the user through a number of incomplete and abstract game creations made by a developer named Coda. Wreden challenges the player to try to come to understand the type of person Coda is from exploring these spaces in a first-person perspective. Within the narrative, the player discovers that Wreden had tried to force meaning onto Coda's games, causing them to end their relationship. 

### Bientot l'&eacute;t&eacute;

<div class="youtube" data-embed="QJe5O7b5JYo"></div>

[From Tale of Tales](https://tale-of-tales.com/bientotlete/)

> Forbes - “Of course, basing a computer game set in the distant future on an examination of the quiet desperation of bourgeois French womanhood in the 1950s is, itself, going to look like non-linear art game weirdness. But there is a plan.” 

### Noby Noby Boy

<div class="youtube" data-embed="d7tisMyOMhk"></div>

[Noby noby boy](https://en.wikipedia.org/wiki/Noby_Noby_Boy)

### Orchids to Dusk

<div class="youtube" data-embed="CWqamSu3qFA"></div>

[Orchids To Dusk](https://polclarissou.itch.io/orchids-to-dusk)

> Orchids to Dusk is a short contemplative wandering experience by Pol Clarissou with music by Marskye. You are an astronaut stranded on an alien planet, with only a few minutes left to live. 

### Niva

<div class="youtube" data-embed="Ytc2BqBhHXg"></div>

[Niva](https://slyce.itch.io/niva)

> NIVA is a pacifistic exploration art game. The player slips into the role of a mighty forest god to restore the harmony in a mesmerizing forest and relieve it of a mysterious infestation. This shuddersome, mothlike infestation is drawn to the conflicts of the forest's inhabitants. Through observation and by using the abilities of nurturing and withering fascinating plants the player can solve said conflicts. NIVA's scenic art style, relaxing music and simple but intriguing game mechanics invite to explore the forest and have a rest from the stressful everyday life.

### Walden

<div class="youtube" data-embed="OEJ_59hVPgw"></div>

[Walden](https://gameinnovationlab.itch.io/walden)

> Play as philosopher and naturalist Henry David Thoreau in his experiment in self-reliant living at Walden Pond. Live off the land, seek out the small wonders and beauties of the woods, and find balance between your need to survive and your desire to find inspiration.


### Localhost

<div class="youtube" data-embed="tg1D-pVhaxk"></div>

[Localhost](https://sophiapark.itch.io/localhost)

> It's your first day on the job in the last days before the singularity. You're undoubtedly a valuable addition to our team. We hope you'll find in our era of machine governance, the repair trade is a noble pursuit.

### Mu Cartographer

<div class="youtube" data-embed="lAiUeZUmtuc"></div>

[Mu Cartographer](https://titouanmillet.itch.io/mu-cartographer)

> Mu Cartographer is a contemplative game experience that combines colourful sandbox and experimental treasure hunt.


### Everything

<div class="youtube" data-embed="JYHp8LwBUzo"></div>

[Everything](http://www.davidoreilly.com)

> Everything is a beautiful new interactive experience from David OReilly, narrated by the late great philosopher Alan Watts.

### Ian Cheng

<div class="youtube" data-embed="ixydT753_Ag"></div>

[Ian Cheng](http://iancheng.com) -- [wikipedia page](https://en.wikipedia.org/wiki/Ian_Cheng)

One of the few artists to have exhibited game/simulations at major art events and venues (such as MOMA New York). Cheng creates 'simulations' as games that play themselves.

---

More!

[Edible Games](http://jennsand.com/edibleGames/overview.php)

[Robert Yang](http://www.debacle.us/#work)


----

## Introduction to VR

- "An artificial world that consists of images and sounds created by a computer and affected by the actions of a person who is experiencing it." - Merriam-Webster
- "Computer technologies that use software to generate realistic images, sounds and other sensations that replicate a real environment (or create an imaginary setting), and simulate a user's physical presence in this environment, by enabling the user to interact with this space and any objects depicted therein using specialized display screens or projectors and other devices. " - Wikipedia

VR has also been defined as inducing targeted behaviour (such as having a designed experience) in an organism by using artificial sensory stimulation, while the organism has little or no awareness of the interference. The 'no awareness' condition has elsewhere been more eloquently articulated as **'the illusion of non-mediation'**. 


### A brief history of VR

![cave](http://upload.wikimedia.org/wikipedia/commons/1/1e/Lascaux_painting.jpg)

30,000 BCE-: From the firelit cave paintings of Lascaux to the birth of painting, architecture, and other arts, we have been attempting to recreate both the world around us and our imagination within.

![butterfly](http://upload.wikimedia.org/wikipedia/commons/c/c1/Dschuang-Dsi-Schmetterlingstraum-Zhuangzi-Butterfly-Dream.jpg)

4thC BCE: Zhuangzi dreams he is a butterfly, but questions if he is a butterfly dreaming he is a man. Are dreams also simulations? 

> Once Zhuang Zhou dreamed he was a butterfly, a fluttering butterfly. What fun he had, doing as he pleased! He did not know he was Zhou. Suddenly he woke up and found himself to be Zhou. He did not know whether Zhou had dreamed he was a butterfly or a butterfly had dreamed he was Zhou. Between Zhou and the butterfly there must be some distinction. This is what is meant by the transformation of things.
> During our dreams we do not know we are dreaming. We may even dream of interpreting a dream. Only on waking do we know it was a dream. Only after the great awakening will we realize that this is the great dream.

![cave](http://upload.wikimedia.org/wikipedia/commons/b/b1/Platon_Cave_Sanraedam_1604.jpg)

~380 BCE: Plato likens the uneducated to prisoners in a cave unable to turn their heads. A fire behind them casts shadows of puppets, also behind them, such that all they can see are the puppets' shadows on the wall in front. Such prisoners mistake appearance for reality. (The allegory is intended to show that the names we give for things, to allow us as prisoners to converse about what we see, are in fact names for things that we cannot see, but only grasp with the mind. That is, the real meaning of the words we use is not something that we can ever see with our senses alone. But we can only know this by being liberated from the illusion of the shadows.)

1637-1672: René Descartes invents conventions for analytic geometry and algebraic approaches to geometry; for which reason we still describe space in X, Y and Z axes and call this "Cartesian" coordinates. He believed that algebra was a method to automate reasoning. 

Descartes also uses methodological skepticism to question his existence and perception, and whether he is dreaming or things are externally real. Influenced by the mechanical automatons of his time, he draws attention to the problem of the connection between body and mind, inadvertently launching a dualism that dominates Western thought thenceforth and remains an influence over and problem of VR. 

> "VR opens the door to what Jaron Lanier (who coined the term virtual reality in the 1980s) calls “post-symbolic communication”: No longer are we limited to communicating via sequences of symbols represented by audible vibrations of our vocal chords, or produced by our fingers pressing on a series of keys or, more recently, a flat piece of glass. Instead, you experience my dream directly, without having to interpret long strings of verbal or written symbols... The medium, the place where those stories will unfold, exists within our consciousness. We’ll find ourselves having passed through our long-held, precious frames to live within those stories. And we’ll carry the memory of those stories not as content that we once consumed, but as times and spaces we existed within." - [source](http://virtualrealitypop.com/futureofvr-8be30f0fca6a#.n1s3d4n92)

![panorama](http://upload.wikimedia.org/wikipedia/commons/3/3a/Cross-section-of-the-rotund_0.jpg)

1800's: The popular wave of massive-scale panorama paintings, often with dedicated buildings, usually depicting landscapes and/or historic events. 

At the same time, the first attempts to capture permanent images from camera obscura (themselves inspired by caves...) through chemical means marks the birth of photography.

1838: Sir Charles Wheatstone invents [stereoscopic photography](http://www.youtube.com/watch?v=Pu6SOckMxT0&feature=youtu.be).

1885/1935: L'Arrivée d'un Train 

<div class="youtube" data-embed="b9MoAQJFn_8"></div>

The train moving directly towards the camera, shot in 1895, was said to have terrified spectators at the first screening, a claim that has been called an urban legend. What most film histories leave out is that the Lumière Brothers were trying to achieve a 3D image even prior to this first-ever public exhibition of motion pictures, and later re-shot the film in stereoscopic 3D, first screened in 1935. Given the contradictory accounts that plague early cinema and pre-cinema accounts, it's plausible that early cinema historians conflated the audience reactions of the 2D and 3D screenings of L'Arrivée d'un Train.

1901: L. Frank Baum, an author, first mentions the idea of an electronic display/spectacles that overlays data onto real life (in this case 'people'), it is named a 'character marker'.

1935: Stanley G. Weinbaum's short story "Pygmalion's Spectacles" describes a goggle-based virtual reality system with holographic recording of fictional experiences, including smell and touch: "You are in the story, you speak to the shadows (characters) and they reply, and instead of being on a screen, the story is all about you, and you are in it."

![viewmaster](http://upload.wikimedia.org/wikipedia/commons/f/f5/View-Master_with_Reel.jpg)

1939: The ViewMaster stereoscopic device is launched.

1943: Patent filed for a head-mounted stereo TV.

1929-1950s: Link Trainer, a mechanical flight simulator with motion simulation, used by over 500,000 pilots.

![3dcinema](http://i2.cdn.turner.com/money/dam/assets/160726073325-3d-glasses-1952-780x439.jpg)

1950s-60s: The "golden era" of 3D cinema. 

![sensorama](http://upload.wikimedia.org/wikipedia/commons/d/dc/Sensorama-morton-heilig-virtual-reality-headset.jpg)

1957–62: Morton Heilig, a cinematographer, creates and patents a mechanical simulator called Sensorama with visuals, sound, vibration, and smell. Heilig later (1960) filed a patent for a multisensory HMD.

![hmd](http://patentimages.storage.googleapis.com/pages/US2955156-1.png)

> "When anything new comes along, everyone, like a child discovering the world, thinks that they've invented it, but you scratch a little and you find a caveman scratching on a wall is creating virtual reality in a sense." - Morton Heilig

![philco](http://wearcam.org/ar/philco_hmd_l.png)

1961: Philco Headsight is the first HMD, used for remote camera viewing (CCTV), including head orientation tracking.

1963: Ivan Sutherland's Sketchpad, one of the first interactive graphics program.

<div class="youtube" data-embed="USyoT_Ha_bA"></div>

[![Personal Television from Life Magazine.](http://cdn.arstechnica.net/wp-content/uploads/2010/04/tvglasses.jpg)](http://arstechnica.com/tech-policy/2010/05/ralph-124c-41-a-century-later/)   
Hugo Gernsback (of "Hugo Awards" fame), wearing his TV Glasses in a 1963 Life magazine shoot.

1964: New York inventor and holographer Gene Dolgoff, who is also the inventor of the digital projector, creates a holography laboratory. Dolgoff's obsession with holography included theories of "matter holograms", the holographic nature of the universe, and the holographic nature of the human brain. 

1965: Ivan Sutherland pens [The Ultimate Display. Ivan E Sutherland, 1965](http://worrydream.com/refs/Sutherland%20-%20The%20Ultimate%20Display.pdf), inspiring everything from the Holodeck to the Matrix. 

> "The ultimate display would, of course, be a room within which the computer can control the existence of matter. A chair displayed in such a room would be good enough to sit in. Handcuffs displayed in such a room would be confining, and a bullet displayed in such a room would be fatal. With appropriate programming such a display could literally be the Wonderland into which Alice walked."

![Sword of Damocles](http://blog.modernmechanix.com/mags/qf/c/PopularScience/4-1971/med_vr_goggles.jpg)

1968: Ivan Sutherland's Sword of Damocles, widely considered to be the first virtual reality (VR) and augmented reality (AR) head-mounted display (HMD) system. DARPA. 


<div class="youtube" data-embed="NtwZXGprxag"></div>

The next twenty years see slow but non-stop development of VR technologies largely within military, industry, and science research institutions, with a slow infiltration into popular culture.

![holodeck](img/holodeck.jpg)

1974: The Holodeck concept appears in Star Trek: the Animated Series, and reappears in 1987 in Star Trek: The Next Generation.

1975: Myron Krueger creates Videoplace to allow users to interact with virtual objects for the first time. Book "Artificial Reality" articulates an artform whose primary material is real-time interaction itself.

<div class="youtube" data-embed="dmmxVA5xhuo"></div>

1977: Star Wars features a hologram (Leia's message for Kenobi) and some of the first widely-seen 3D computer graphics in film (the Death Star plans).

![aspen](http://upload.wikimedia.org/wikipedia/commons/4/48/QADAS.jpg)

1978: [Aspen Movie Map](http://en.wikipedia.org/wiki/Aspen_Movie_Map) -- a proto Streetview, interactive via laserdisc, that also had a polygonal mode.

<div class="youtube" data-embed="2Ytd12d6qNw"></div>

1979: LEEP HMD with lenses designed for very wide field of view.

1980: Steve Mann creates the first wearable computer, a computer vision system with text and graphical overlays on a photographically mediated reality.

![battlezone](http://cdn.mos.cms.futurecdn.net/e3a677f2f9d2dc35ec1a16862d376c25-650-80.jpg)

Battlezone is the first big 3D vector graphics success in arcade games. Battlezone was thought so realistic that the US Army used it to train tank gunners.

1982: Atari founds a VR research lab

[Tron](http://en.wikipedia.org/wiki/Tron) movie

1983: Brainstorm movie.

1984: William Gibson writes [Neuromancer](http://en.wikipedia.org/wiki/Neuromancer), bringing wide acclaim to the cyberpunk genre.

![elite](https://upload.wikimedia.org/wikipedia/en/c/c4/BBC_Micro_Elite_screenshot.png)

Elite, an open world space trading video game, published by Acornsoft for the BBC Micro and Acorn Electron computers, featuring revolutionary 3D graphics

1985: Jaron Lanier (formerly of the Atari lab) coins the phrase Virtual Reality and creates the first commercial business ("VPL") around virtual worlds.

VR at NASA:

<div class="youtube" data-embed="NAuytnYU6JQ"></div>

1988: The Legible City. Jeffrey Shaw

<div class="youtube" data-embed="61l7Y4MS4aU"></div>

[See documentation here](http://www.jeffrey-shaw.net/html_main/show_work.php?record_id=83)

- Conceived as a break from cinema, in which the image is directed by the viewer (cyclist). 
- Drift / derive

1989: [Shadowrun](http://en.wikipedia.org/wiki/Shadowrun) desktop role-playing game in a near-future cyberpunk + VR world

The 90's saw a wave of public interest and hype in VR, which as it grew became often conflated with cybernetics, AI, computer graphics in general, the nascent internet, etc. as *cyberspace*.

1991: Virtuality company launches with a new multiplayer hardware prototype in several countries -- but at $73,000 per unit! Sega also launches a VR headset for their console.

![CAVE](http://upload.wikimedia.org/wikipedia/commons/6/6d/CAVE_Crayoland.jpg)

EVL in Chicago launches the first cubic CAVE VR system. Later commercialized by Mechdyne, WorldViz and others, still actively installing new systems in research labs around the world today.

Retinal display developed, scanning images onto retina, commercialized by Microvision. (Antecedent of tomorrow's MagicLeap).

Computer Gaming World magazine predicted "Affordable VR by 1994"

ABC Primetime covers the VR scene (from [vrtifacts.com](http://vrtifacts.com/virtual-reality-1991-many-believe-it-will-revolutionize-the-way-we-live/)):

<div class="youtube" data-embed="c5ZnWNilMxw"></div>

1992: Neal Stephenson writes [Snow Crash](http://en.wikipedia.org/wiki/Snow_Crash)

Lawnmower Man movie.

Sega Virtua Racing, and Virtua Fighter (1993) popularized polygonal 3D games.

1994: The first version of Virtual Reality Modeling Language (VRML), a standard for sharing interactive  3D vector graphics on the web, and by 1997 several 3D chat environments exist.

1995: Maurice Benayoun creates a VR artwork **Tunnel under the Atlantic** connecting the Pompidou Centre in Paris and the Museum of Contemporary Art in Montreal with 3D modeling, video chat, spatialized sound, and AI.

Strange Days and Johnny Mnemonic movies.

Char Davies creates [Osmose](http://www.immersence.com/osmose/), a pinnacle of VR art.

![Osmose](http://www.immersence.com/centralizedImages/osmose/Osm_Tree_600@2x.jpg)

- Char Davies was painter, and became a co-founder of SoftImage (later Autodesk)
- Wanted to **demonstrate medium's potential**, and "aspects related to the medium of "virtual reality" that are often overlooked"

---

However, the same year was also identified as the 'death of VR'. Nintendo releases [VirtualBoy](http://en.wikipedia.org/wiki/Virtual_Boy) for US$ 180, and discontinues it just six months later. [("Nail in the coffin for 90's VR")](http://vrtifacts.com/virtual-boy-another-perspective/) A survey by Computerworld magazine in 2007 listed VR as the 7th biggest technology flop in history.

**What went wrong?**

- Inadequate Image Resolution
- "Motion to photon latency" too high
- Limited Position Tracking
- Cumbersome Equipment
- Lack of Interpretation of Body Movements
- Simulation Sickness
- Cost
- Slow computers
- Poor software design
- Lack of data/understanding the human body, lack of haptics research etc.
- Premature launches & inflated expectations
- Charlatans
- Concern about liability (user accidents)
- Single-user problem
- No consumer "killer app"

 
![quake](http://cdn.mos.cms.futurecdn.net/95c21aa0e5964acbd5ace2d37740fa6a-650-80.jpg)

1996: Quake pioneers play over the Internet first-person shooters. 

3dfx Interactive released the Voodoo chipset, leading to the first affordable 3D accelerator cards for personal computers. [Within a few years dedicated 3D graphics processing unit cards (GPUs) become essential for most video games, and GPU performance wars rapidly increase real-time 3D rendering capabilities at consumer price levels.](http://www.techradar.com/news/gaming/the-evolution-of-3d-games-700995/2)

Meanwhile, although VR was still capturing some SF attention and slowly being rediscovered through the web, VR develops mainly in research labs, and steadily continues to grow in big-budget industrial, science & health research, as well as military training, outside the media radar.

> "VR was used to visualize oil fields and to visualize machinery to extract oil more efficiently from old fields. Similar things happened in medicine. We understand more about large molecules, we understand more about how the body heals from surgery through VR simulations." - [Whatever happened to VR -- interview with Jaron Lainer (2007)](http://www.10zenmonkeys.com/2007/03/09/whatever-happened-to-virtual-reality/)

1999: [The Matrix](http://en.wikipedia.org/wiki/The_Matrix) movie, and eXistenZ.

2001: Grand Theft Auto III released, popularizing open world games with a non-linear style of gameplay

2005: [The AlloSphere](http://www.allosphere.ucsb.edu)

<div class="youtube" data-embed="u-D-zEToJQ4"></div>

Over this period it also gradually begins to appear on the web.

![SL](http://upload.wikimedia.org/wikipedia/commons/c/c6/Second_Life_11th_Birthday_Live_Drax_Files_Radio_Hour.jpg)

1999: Entrepreneur Philip Rosedale forms Linden Lab to develop hardware for 360 degree VR, but this soon transforms into a platform for 3D socializing, launching SecondLife in 2003.

2007: Google Streetview launched.

**VR goes into the garage, then goes mainstream again**

2009: [A teenage Palmer Luckey announces on a BBS post his home-made Oculus "Rift" HMD.](http://www.mtbs3d.com/phpbb/viewtopic.php?f=120&t=14777)

2011: Now 18, Palmer hacks together a rough prototype in his parents’ garage in Long Beach, California.

2012: John Carmack (lead programmer of Doom, Quake, and many other pioneering 3D games) introduces a duct taped head-mounted display based on Luckey's prototype at the Electronic Entertainment Expo. Palmer's company, Oculus VR, launches [a Kickstarter campaign](http://www.kickstarter.com/projects/1523379957/oculus-rift-step-into-the-game) to fund the development of the Rift. It is phenomenally successful,  raising US$2.4 million for the development of the Rift. 

<div class="youtube" data-embed="DhcOMOWRMnA"></div>

2013: First Oculus Rift developer kit (DK1) ships, for $300. Developer kits are released to give developers a chance to develop content in time for the Rift's release; these have also been purchased by many virtual reality enthusiasts for general usage.

2013: Google announces an open beta test of its Google Glass augmented reality glasses.

2014: Second Oculus Rift developer kit (DK2) ships, for $350. More than 100,000 DK2's shipped by 2015. Oculus VR is acquired by Facebook for $2 billion.

2015: Microsoft announces HoloLens augmented reality headset.

HTC partners with Valve Corporation to develop the HTC Vive headset and controllers, released early 2016.

---

2016: "the year of VR"

- Sony, Facebook, Google, Microsoft, Samsung, Valve, nVidia, Apple and many other large corporations gambling on VR's success. 
- Why now?
	- Technological feasibility & affordability
		- Advances in small displays (thanks to cellphone industry)
		- Advances in 3D graphics (thanks to gaming industry)
	- Gaming industry crisis? Looking for the next big thing?
- Slow rise/uptake. Still not exactly cheap!
- 360 video vs. "real" VR (becoming a polemic)
- Seated vs. room-scale VR (perhaps more temporary)
- SteamVR vs. Oculus Home vs. Viveport (content delivery networks)

Hardware:
- Two consumer PC-tethered headsets (Oculus Rift, HTC Vive) 
	- started shipping in May, hit major stores by summer.
	- currently tethered to PC by cable, but untethered expected to come
- One console-based headset (Playstation VR)
- Several cellphone-based devices 
	- Better quality: GearVR
	- More budget: Google Cardboard, Daydream
	- lower resolution/FPS, but $99 or less + phone
	- position tracking developing
- Lots of other variants and upcoming devices, e.g. OSVR
	
**Rift | Vive + PC specs**

- **Resolution**: 2160 x 1200
- **Refresh rate**: 90 fps
- **Field of view**: 110 degrees
- **Tracking area**: 5 x 11 feet | 15 x 15 feet
- **Video**: no input | front-facing camera
- **Audio**: mic + headphones | mic + headphone jack
- **Price**: ~USD$800 including hand controllers

But that price doesn't include the PC... add another $2000 or so for:

- **GPU:** NVIDIA GTX 970 / AMD R9 290 equivalent or greater
- **CPU:** Intel i5-4590 / AMD FX 8350 equivalent or greater
- **Memory:** 8GB+ RAM
- **Video Output:** HDMI 1.4 or DisplayPort 1.2 or newer
- **USB:** 3x USB 3.0 ports plus 1x USB 2.0 port
- **OS:** Windows 7 SP1 64 bit or newer

2017 onward:

Untethered HMDs and improved display, hand-tracking, eye-tracking, etc.

[![vrfund](http://www.thevrfund.com/wp-content/uploads/vr_industry_aug2016.png)](http://www.thevrfund.com)

It's not 1995 -- there's huge investment, affordable platforms, ready authoring tools and delivery networks, and proven use cases. 

[VR and AR are the next mega tech themes through to 2030; with today likened to the state of mobile phones 15 years ago. Major mainstream adoption predicted for 2025. VR will be the first phase, followed by AR. Content market expected to reach $5.4B by 2025.](http://cdn.instantmagazine.com/upload/4666/piperjaffray.f032beb9cb15.pdf)

Soon-to-emerge tech in AR: Microsoft HoloLens, Meta, Magic Leap (massive investments), Tango, etc.

[Augmented/Virtual Reality revenue forecast revised to hit $120 billion by 2020](http://www.digi-capital.com/news/2016/01/augmentedvirtual-reality-revenue-forecast-revised-to-hit-120-billion-by-2020/#.WBCt8Fdy7y8)

![hype cycle](http://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Gartner_Hype_Cycle.svg/559px-Gartner_Hype_Cycle.svg.png)

- Are we in the beginning of the plateau of productivity, or in another hype cycle? [For more on hype cycles](http://www.gartner.com/newsroom/id/2575515) -- Gartner in 2013 placed the plateau for VR in the 5-10 year range.

> (See also [The Rise and Fall and Rise of Virtual Reality](http://www.theverge.com/a/virtual-reality/) and [Introduction to Virtual Reality](http://www.slideshare.net/marknb00/comp-4010-lecture-1-introduction-to-virtual-reality))

### The message of the medium

VR and AR expected to disrupt not only games and film, but also music, advertising, social media, education, travel, and who knows what else (maybe Black Mirror does). But do we know what we are doing?

> Palmer Luckey, Oculus CEO: "I think it will be VR content and software that will drive the industry long term". 

> Richard Marks, Sony Magic Lab: "Wild West... there are no established genres. You don't get that opportunity very often." 

> Michael Abrash, Chief Scientist, Oculus: "The future of VR lies in the unique experiences that get created in software, and if I knew what those would be, even in broad outline, I would be very happy." 

It is even obvious in the instability of terminology. Is it a game, a film, an experience, a simulation, a world, ...? Are we audience / viewer / visitor / cybernaut / immersant / player / user ...?

---

> "A new medium can suggest a multitude of approaches. In 1929, Dziga Vertov's [The Man with the Movie Camera](http://www.youtube.com/watch?v=z97Pa0ICpn8) catalogued possibilities for the evolution of film. From narrative structures to special effects, it shows *what cinema could have become*. Virtual reality occupies a similar historical moment--it is unformed and hence its possibilities seem unconstrained."

> "Although the artistic community has often been excluded from the development of new technologies, this situation is changing. Artists no longer sit on the sidelines eventually to become grateful users of borrowed tools but have become active in development, creating a disturbance in the field with new contingencies... A new medium like Virtual Reality challenges traditional conventions not because the participant wears a helmet or glove but because it suggests new relationships between the viewer and the viewed... Unfortunately, as the medium of virtual environments becomes more and more defined, different approaches will be ignored, abandoned, or forgotten as the medium coalesces into a mature form." - Douglas MacLeod, Director of the Banff Art and Virtual Environments Project, in the preface of Moser, Mary Anne, and Douglas MacLeod. [Immersed in technology: art and virtual environments. MIT Press, 1996.](http://mitpress.mit.edu/books/immersed-technology), emphasis added.

The above citation neatly echoes the aims of this course. In 2016, twenty years since this was written, and nearly fifty years since virtual reality's birth, it is finally becoming a widely-available consumer medium. 

> "...in these early stages of the VR lifespan, a common mishap is occurring: content creators shoehorning old formats into new technologies. As we explore this new medium, we are building on the backs of film, theater, narrative games and visual art to takes cues as to what to create in VR." [Will Virtual Reality and 360° Film Experience an Industry Divide?](http://vrscout.com/news/virtual-reality-and-360-film/)

Instead of shoehorning, what can earlier developments of cinema, game, performance and visual (and sonic) arts tell us about the the explosion of virtual reality (VR) in our imminent future? Theories, methods, and unique modes of expression have yet to be established by the collision of gaming technology with cinema. As with any emerging medium, a willingness to break rules, abandon habits and re-learn is necessary.

> "Hayao Miyazaki is [quoted](https://youtu.be/jtTBYMvLBbw) as making the following observation: "[anime] is produced by humans who can't stand looking at other humans.” I am proposing that this observation is not limited to anime. Much of what our culture makes seems to be made against, rather than for, other humans. Cities made for cars and rent extraction are simply a very large, indeed inescapable symptom of the and disease. We could say the same for industrialized art and music and nearly every globalized thing we come into contact with. The issue ... is the difference between the imagined, idealized vision, and its eventual commodification. For a brief moment, each new technology opens a space of freedom and opportunity. It is easy to mistake this space for something permanent. In reality, it is just the wave receding before the next tsunami. Whatever freedom can exist will have to be found on a different shore. For the creative person, this is adventure and excitement and possibility. But for everyone else, the tsunami can be devastating." - Marcos Novak

[![Codex](img/codex.jpg)](http://en.wikipedia.org/wiki/Codex_Seraphinianus)


### The illusions of VR

- Film/animation depends on a perceptual illusion -- [persistence of vision](http://en.wikipedia.org/wiki/Persistence_of_vision). This is easier to understand via animation: around 12-15 frames per second is enough for the brain to interpret as movement, but only when sequent images are plausible enough to be fused. *Plausibility* in this case is a function of neurophysiology and cognition. (Of course, cinema also depends on other perceptual quirks, such as the brain's acceptance of cuts in editing even though nothing like a cut exists in real life, the suspension of disbelief through non-human perspectives, and so forth.)

- Stereoscopic 3D (S3D) builds on another perceptual illusion. Presenting to each eye a viewpoint slightly displaced laterally emulates the *parallax effect* -- one of the most powerful visual cues to impart depth (distance). Again, this is dependent on the human body, and also requires very careful alignment. Some, though few, people experience discomfort due to discrepancies between the stereoscopic 3D depth cue and others that are lacking, such as vergence.

Virtual reality depends on both of these illusions, and others such as egocentric spatialized audio, and greatly benefits from wide field of view, high resolution, and other factors of **immersion**. 

- The crucial addition for VR is *head tracking*, which means we can present a coherent image regardless of what direction we face. This illusion breaks down if the delay between movement and image (motion-to-photon) is greater than a couple of handfuls of milliseconds, which underlies the need for high frame rates (90fps for current desktop models) to avoid nauseating "judder". 

- This illusion is greatly enhanced by *position tracking*: matching the lateral movements of the head as well as its orientation, so that you can look around, over and under things, and generally benefit from more kinds of depth cues we experience in real life, as well as further reducing the chance of nausea.

The result is that the viewer no longer perceives an image plane worn in front of the eyes, and instead perceives oneself being present in another world. Instead of an image moving in front of your eyes, the world appears as a fixed space in which you are moving your own head. (This also means that stereoscopic content can be as close as your nose, something that S3D cinema cannot normally achieve because of the limits of the frame).

- The combination of all the above can create a compelling immersive experience. Instead of an image moving in front of your eyes, the world appears as a fixed space in which you are moving your own head. Together with the qualities of content, this leads to the evocation of **presence**, the sense of actually being-there in the world; a continuous illusion of non-mediation. 

- But aside from presence, VR also maximizes interaction (the extent to which a user can manipulate objects and the environment of the system) and autonomy (the system's ability to receive and react to external stimuli, such as actions performed by a user). In that regard, convincing experiences created by **real-time simulations that support agency** -- the ability to take meaningful action in a world and discover meaningful consequences -- are just as essential.

### Nausea and Simulator Sickness

> Simulation Sickness is a syndrome, which can result in eyestrain, headaches, problems standing up (postural instability), sweating, disorientation, vertigo, loss of colour to the skin, nausea, and - the most famous effect - vomiting. It is similar in effects to motion sickness, although technically a different thing. Simulation sickness can occur during simulator or VR equipment use and can sometimes persist for hours afterwards... If VR experiences ignore fundamental best practices, they can lead to simulator sickness—a combination of symptoms clustered around eyestrain, disorientation, and nausea. - [Article on Gamasutra - by Ben Lewis-Evans on 04/04/14](http://www.gamasutra.com/blogs/BenLewisEvans/20140404/214732/Simulation_Sickness_and_VR__What_is_it_and_what_can_developers_and_players_do_to_reduce_it.php)

Simulator sickness involves three kinds of issues:

- Oculomotor
	- Headaches, fatigue, eye strain, can't focus
- Nausea
	- Sweating, salivation, can't concentrate, burping/stomach awareness
- Disorientation
	- Blurry vision, dizziness (with eyes open or closed), vertigo (24%)

Which is to say, *virtual worlds can be dangerous!* See this 1996 NBC special:

<div class="youtube" data-embed="O0arluK5zrQ"></div>

In fact simulator sickness has been known about since the earliest flight simulators of the 1950's, but is still not fully understood. It is clearly triggered by "cue conflicts", whereby what some parts of the visual system are reporting does not match what other sensory components (such as proprioceptive systems) are reporting. 

(Some researchers hope to alleviate VR nausea by galvanic vestibular stimulation, [for example the Mayo Clinic](http://ir.net/news/virtual-reality/124021/mayo-clinic-vr-nausea/), but as yet this hasn't convinced the industry. [See also this](http://uploadvr.com/vr-sim-sickness-combated/
).)

Some people are far more or less susceptible than others. It generally affects younger people less, and tends to reduce with increased exposure (getting your "VR legs"). People with a history of MS, alcohol/drug abuse, etc. also tend to be more susceptible.

> Around 5% of all individuals will never acclimate regardless how much they try to build a resistance to it meaning there is a confirmed minority of individuals who will never be able to us Virtual Reality as a mainstream product over their lifetime. - [Sim Sickness guide on Oculus forums](https://forums.oculus.com/viewtopic.php?t=170)

Since nausea/sim-sickness remains one of the greatest risks to virtual reality's success, it is essential to consider in the design of an experience. 

> Virtual reality’s biggest enemy is bad virtual reality.  – Palmer Luckey

> The fear is if a really bad V.R. product comes out, it could send the industry back to the '90s, – John Carmack

### Latency

To some extent this is a hardware problem -- and recent advances in VR hardware and drivers have come a long way to minimize the risk. However this still very deeply affects how we design our content, and is important to understand.

- Latency is how long it takes for a message to transmit. *Motion to photon* latency measures how long it takes for a change in head rotation to be reflected in a change in the image perceived. It should be *consistently* under 20 milliseconds to avoid nausea. Failing to do so can result in  sluggish or sloppy motion tracking, in which the world 'swims' around you. Even occasional hiccups will be experienced as a disturbing "judder" that is never experienced in normal life. The Oculus and Vive hardware now run at 90 fps and their drivers do some tricks to help keep latency down, but it also depends crucially on the content and quality of the software. 
	
- Anything that can potentially interrupt or slow down rendering, or delay the motion-to-photon pathway, has to be avoided to prevent nausea. The need for low-latency and high-framerate is one of the reasons why certain visual details and effects common in video games are eschewed in VR. When the world surrounds in you stereoscopy, geometry is often more important than screen-based post-processing. In particular, many effects popular in games are actually rendered across several frames -- this is simply not viable for VR. The Unreal VR template disables such effects by default. 

- A related issue is image persistence: a low-persistence image has a longer black interval between presenting frames, which reduces the smear/blur/ghosting when moving your head. This is mainly a display screen technology issue and largely resolved in current generation hardware. 

![Persistence](https://lh5.googleusercontent.com/bS3bZRKphnYPK1IAP7DwYN6e3Y_7y6-8RnHVutmm15S_wjzkf4M1vDR0OczN0kHx6PVd-10jd4vmhDFNhY0I18_31ovaKI2s6X_noyC9jk0AutfhEM4BIvnNyFjS6Q)

### Motion cue conflicts

The other major cause of nausea is motion cue conflicts, in which the movement portrayed by the images presented is not consistent with real motion of the body (or with an expected motion). This is almost the inverse of motion sickness, and appears to trigger a response in the body consistent with an assumption of being poisoned. Modern life has also brought to us another real-world parallel: 

> Imagine you’re on a train and look out the window to see a train leaving the station. As that train begins to move it creates an illusion of movement in your own mind and your brain’s likely conclusion is that the train you are on is actually moving in the opposite direction, that illusion is called “Vection.” Vection occurs when a portion of what you can see moves, and is one of the things that can lead to motion sickness in VR." - [5 ways to reduce motion sickness in VR](http://uploadvr.com/five-ways-to-reduce-motion-sickness-in-vr/) 

Any change of velocity (or rotational velocity, i.e. turning) is an *acceleration*, which imparts a physical force on the body detected primarily via the vestibular system. If such changes occur in the virtual world but are not mirrored in physical vestibular response (e.g. by navigating with a joystick rather than on a treadmill) nausea can very rapidly ensue. 

There are two important categories of motion cue conflicts to consider:
- Virtual motions initiated by the viewer with no physical correlate (**the locomotion problem**)
- Virtual motions not initiated by the viewer (breaking the **HMD-is-the-camera** rule)

### The camera is always head-mounted

It is helpful to **think of the HMD as the camera** into a virtual world that is aligned to the real world. (At [Weird Reality](http://artandcode.com/), I heard several speakers described the HMD as a 'head-mounted camera'). 

> The rendered image must correspond directly with the user's physical movements; do not manipulate the gain of the virtual camera’s movements. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

The golden rule for designers is that we must **never take away control of the camera from the viewer**, not even for a moment. This means no fixed-view cut-scenes or 'cinematics', no full-screen imagery, no lens and framing control, etc. Also no motion blur, depth of field effects etc. (still takes away viewer control). 

> One of the big challenges with VR storytelling lies within the constraints on camera movement forced upon us by this tiny detail called simulator sickness. Quick zoom in to focus on a detail – nope, not possible, you can’t zoom in VR. Nice dolly shot moving around the scene – be careful or the viewer might have a look at what he had for breakfast instead of comfortably watching your experience... the safest bet is not having continuous camera movement at all. - [The limbo method](http://uploadvr.com/introducing-limbo-a-vr-camera-movement-technique-by-the-developers-of-colosse/)

Since the immersant is free to look in any direction they choose, you need to make sure all directions are valid, potentially valuable, and that nothing essential will be missed because 'they were looking the wrong way'. 

It also means that **everything should be in-world**. Nothing should "stick" to the viewer's headset -- not even messages/menus, head-up displays, etc. 

> Maintain VR immersion from start to finish—don’t affix an image in front of the user (such as a full-field splash screen that does not respond to head movements), as this can be disorienting... Even in menus, when the game is paused, or during cutscenes, users should be able to look around. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

User interface elements are uncomfortable if they are stuck to the headset, better if they are transparent overlays that keep the world's orientation, and best if they are actually objects in the world. They could be:

- on walls ![walls](https://twentymilliseconds.com/screenshots/ui-walls-example.png)
- on objects, on screens in world ![screens](https://twentymilliseconds.com/screenshots/vr_typing_hud.png)
- or cockpit, 
- or floating over its subject ![coins](https://twentymilliseconds.com/screenshots/lucky/coins-ui.gif)


### When is camera movement OK?

> Our inner ear detects various changes in velocity, or accelerations, but it doesn’t detect constant velocity. Because of this, developers can have someone moving at a constant speed in a relatively straight line and the simulator sickness effects will be greatly reduced. - [5 ways to reduce motion sickness in VR](http://uploadvr.com/five-ways-to-reduce-motion-sickness-in-vr/)

There *are* plenty of examples of VR projects that also utilize moving cameras, but you can still look around independently on top of this motion. Generally the fixed component of the camera motion is slow, at constant speed, in a straight line in the world, or only in the direction the person is facing. This is the kind of "rails" experience that has been disappointing to many, and still nauseous to some. Senza Peso is an interesting example.

For more complex camera movements an option is to fade out all but the most important elements to minimize visual flow during the movement. This "limbo effect" was suggested by the authors of Colosse in order to allow non-nauseating camera effects -- and it also relies on some (fairly subtle) cues of ground and body orientation, as well as removing most of the elements of the scene to reduce vection (a method they also leveraged for narrative focus):

![colosse](http://uploadvr.com/wp-content/uploads/2015/09/limboBeachSnippet13.gif)

> Notice the subtle points of reference in the scene that are meant to maintain a consistent frame of reference. Somewhat like staring at a single spot on the floor to maintain balance. We used two elements to create this reference frame: a subtle particle effect and a ground plane far below the user. Using short lived particles we were able to create this artificial reference frame without distracting the user. - [Introducing Limbo, a VR camera movement technique by the developers of Colosse](http://uploadvr.com/introducing-limbo-a-vr-camera-movement-technique-by-the-developers-of-colosse/)

In contrast, one of the most disturbing camera motions of all is the oscillating 'head bob' and other 'camera shake' effects often added to games. (The head-bob in particular is right around a 3-5Hz frequency that is particularly nauseous.)

![headbob](https://lh5.googleusercontent.com/fUQXkmhrWdpCi_F9vfbI8U2Ss-zB5O11xn_wNCBbTSJczmjaRefoV26EflYqwgNpgK0hrgC4ZTB372IalQhssSKD98MZ7B8lp04glfqiXpFwICL5MuzlNPBzNaw3MA)

### Collisions

It is also disturbing to be suddenly (unexpectedly) moved in the world because of collisions with objects or other dynamic impacts. However if collisions do not stop camera motion, people will be able to simply walk through walls and poke their heads inside of objects in the world, and float rather than fall, etc. 
- To deal with collisions, some recommend simply fading the image toward black as you get very close to a object's surface, or enter inside of it. This is often enough to naturally guide people away from walls and other surfaces, and also prevents the disturbing vision of a wall made of paper, or the betrayal of the secrets behind it. 
- Similarly, to effect impacts, a dip to black around the movement is an option.

### The locomotion problem

Avoiding motion cue conflicts altogether would limit viewer's exploration of a virtual world to the same physical dimensions of the real room they are in. To explore vaster worlds we must allow people to move virtually but not physically, via **some design compromises that nevertheless minimize triggers of nausea**. [Some say that this locomotion question is the biggest problem for VR.](http://fatedblog.com/2015/08/06/locomotion-simulation-sickness-and-the-fear-of-vr/). 

> "It’s in the interest of all parties to keep faulty reality away from users, and Sony, Valve, and Oculus all have the quality control systems in place in order to do that. Oculus has even devised a new “comfort” rating system, which divides its launch lineup of games into “comfortable,” “moderate,” and “intense” categories." - [Virtual Reality’s Locomotion Problem](http://motherboard.vice.com/read/virtual-realitys-locomotion-problem?trk_source=recommended)

Even being able to turn around to face behind you (rather than looking over your shoulder) is problematic. The classic yaw movement -- a horizontal rotation -- has been described as "VR poison" by John Carmack -- but without it, our worlds will be mostly straight paths... This is really problematic for artists coming from gaming environments -- most people simply can't use mouse or right-stick to change body orientation in the world without becoming sick. 

> Remember that “acceleration” does not just mean speeding up while going forward; it refers to any change in the motion of the user. Slowing down or stopping, turning while moving or standing still, and stepping or getting pushed sideways are all forms of acceleration. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/) 

- Similarly, the kinds of lateral 'strafing' movements that are common to first-person shooter games can be quite disturbing in VR. 
- Moving over uneven ground can create unexpected vertical movements. Either steady the movement, or soften the ground.
- Stairs can be especially unpleasant (both going up and down). Use elevators, or ramps with very shallow inclines.

Finally, walking around a world is really counter intuitive, as you may have to think about two different spaces simultaneously -- the space you can physically move around in, and the space you can navigate around in. 

### Some solutions / compromises

**Just don't do locomotion at all** 

- Create a world that is sufficiently interesting at the scale of a small room
	- E.g. Job Simulator, Fantastic Contraption, I expect you to die, etc.
	- E.g. create a world at a 'tabletop' scale
- Create a world that changes over time around you
	- E.g. Sightline - The Chair
	- E.g. work with scale, zooming into detail or out to macroscopy, rather than change in location

A lot of 2016's sanctioned VR content avoided locomotion.

**Instant accelerations are better than smoothing**

- If you have to change velocities, do it instantaneously rather than gradually. (This differs from the norm in screen-based games, for example). Don't accelerate smoothly: immediately moving and immediately stopping is better (for most people).
	- Same for rotations. Jumping between angles is better than smooth panning (for most people). Cloudhead games calls this "comfort mode": snapping a predictable number of degrees left or right, and holds that this significantly reduces nausea. But for some players this breaks immersion too much, and it can also leave immersants a bit confused as to where they are actually facing.

<div class="youtube" data-embed="Gp0eMNSVtZA"></div>

**Instant transitions (AKA teleport)**

Vive's introductory content The Lab uses this method extensively. It is very low in terms of nausea, but relatively immersion breaking. It also depends on developing a method to identify valid locations to teleport to. 

[It has been argued that we can handle teleports in VR in a similar way that we can handle cuts in TV](https://www.engadget.com/2016/10/07/why-teleportation-makes-sense-in-virtual-reality/)

<div class="youtube" data-embed="nmR8iqXSspA"></div>

It can also become a game mechanic:

<div class="youtube" data-embed="gbp7xX9QPOc"></div>

Unreal's VR template includes teleport support.

**The third person view**

- Many developers have suggested a 3rd person (behind the avatar) viewpoint reduces the nausea. Oculus bundled a 3rd-person platformer ("Lucky's Tale") with the first release.

- A rather more unusual mode of navigation switches into 3rd person while moving, and back to 1st person when stationary.

**Reducing the field of view during motion**

Sim sickness is much less prevalent when the field of view is lesser, however this also reduces immersion & presence. Some suggest reducing FOV only in those moments that could be particularly nauseating. Others have suggested a kind of small FOV preview overlay while moving, that expands out to full screen when movement ends.

<div class="youtube" data-embed="lHzCmfuJYa4"></div>

Reducing the field of view may work because it reduces vection.

**Anchoring (Cockpit) methods**

Placing a reference frame around the point of view can help stabilize the senses -- which is why cockpit-based simulations (inside cars, spaceships, robots, or even just a helmet, etc.) can handle much greater accelerations and rotations without inducing sickness. It might be as simple as having a reference that says which way is "body-forward", but it also taps into the reduced field of view as above.

[However it might be possible that the reference frame is semi-transparent, and even that it is not present for much of the time.](https://www.reddit.com/r/oculus/comments/3yihao/i_solved_vr_sickness_maybe/) -- more research is needed. See also the "canvas mode" [here](http://tore-knabe.com/virtual-reality#MovementExperiments)

**Give them a body?**

Many people report it disturbing to look down and see no body, especially for sedentary experiences. This may be related to giving a reference frame that has a *logical* anchor in the world. However, some say that looking down and seeing somebody else's body is equally disturbing, and others have shown that even a reference frame with no ontological sense can help. More research needed!

> A virtual avatar ... can increase immersion and help ground the user in the VR experience, when contrasted to representing the player as a disembodied entity. On the other hand, discrepancies between what the user’s real-world and virtual bodies are doing can lead to unusual sensations (for example, looking down and seeing a walking avatar body while the user is sitting still in a chair). - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

![nose](http://www.wired.com/wp-content/uploads/2015/04/vrnosetuscany.gif)

[Research at Purdue suggests that overlaying the peripheral image of a nose helps reduce simulator sickness by 13.5%](http://www.wired.com/2015/04/reduce-vr-sickness-just-add-virtual-nose/)

Again, a non-realistic body might be better than a pseudo-realistic body. Perhaps it need not even be human (or humanoid). This removes issues of mismatch size, gender, skin color, age, etc that could create cognitive dissonance. Alternatively, give immersants control over their avatar appearance.

> When it comes to modeling player avatars in VR, abstract trumps the real. Malaika says Valve has found that players tend to feel less immersed in games that try to model hands realistically, and more immersed in games with cartoony hands. - [Valve advice for VR](http://www.gamasutra.com/view/news/250362/Valve_shares_advice_on_designing_great_VR_game_interactions.php)

**Redirected walking**

The notion here is that while walking in the real space, the virtual world is slightly rotated (below perceptual levels). Although we feel we are walking in a straight line in the virtual space, we are in fact walking in circles in the real world. Problem: still requires much larger spaces than most rooms.

<div class="youtube" data-embed="KVQBRkAq6OY"></div>

A related method is 1:X motion, in which moving 1 meter in the real world may move you more than 1 meter in the virtual space. Horizontal exaggeration appears to not induce nausea, but vertical movement should remain 1:1.

<div class="youtube" data-embed="At_Zac4Xezw"></div>

**Displacement of motor functions**

Disturbance is reduced if some body actions accompany a movement. Some games use a 'running in place' or 'paddling with the hands' behaviour to trigger walking in the virtual space:

<div class="youtube" data-embed="15lvlAEHXww"></div>

Or swimming etc.:

<div class="youtube" data-embed="MjwNItck_Vg"></div>

Or grappling hooks:

<div class="youtube" data-embed="3Ore5DG1qT0"></div>

Other experiences use the direction of the hands or fingers to indicate direction of motion, which appears to reduce nausea.

---

Overview of locomotion methods:

<div class="youtube" data-embed="p0YxzgQG2-E"></div>

[Another overview here](http://ignite-vr.com/blog/2016/09/24/locomotion-in-vr/)

Many of these solutions are utilized in EagleFlightVR, which has had [very strong reviews commenting about the lack of nausea](http://www.roadtovr.com/eagle-flight-review-vr-psvr-htc-vive-oculus-rift/).

<div class="youtube" data-embed="4TJdTB5qQjA"></div>

### Other forms of disturbance

> Avoid visuals that upset the user’s sense of stability in their environment. Rotating or moving the horizon line or other large components of the user’s environment in conflict with the user’s real-world self-motion (or lack thereof) can be discomforting.  - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/) 

***Spatial***

- The head-height above ground should be consistent with the immersant's own height, whether sitting or standing. 
- Real-world movement is more comfortable. Humans walk at ~1.4 meters per second (this is much slower than 'walking' in most video games).
- Objects drawn from the real-world should have consistent and usually accurate scale.
- On the other hand, miniature worlds work well -- about table-sized + 3rd person view
- Avoid confined spaces.
- No image-based effects such as particles, as they can look flat and break stereoscopy.

**Lighting & texturing**

- Avoid very bright lights, flickering lights, and areas of high contrast -- especially in peripheral vision.
- Avoid flicking and flashing, especially in peripheral vision.

> Refrain from using any high-contrast flashing or alternating colors that change with a frequency in the 1-30 hz range. This can trigger seizures in individuals with photosensitive epilepsy. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

- Avoid untextured surfaces, as the lack of detail provides less distance cue and weakens the perceptual illusion, making other conflicting signals more problematic.
- On the other hand, avoid high-contrast textures, which are more likely to cause flickering due to aliasing noise.
- Avoid textures that are obviously repetitive, like tiling patterns. Any high-spatial frequency repetition can give discomforting perceptual signals. They can also trigger photosensitive epilepsy.
- For the same reason, avoid very thin objects, and avoid very regular or straight objects -- irregular/random/organic shapes are more comfortable.

> The images presented to each eye should differ only in terms of viewpoint; post-processing effects (e.g., light distortion, bloom) must be applied to both eyes consistently as well as rendered in z-depth correctly to create a properly fused image. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

**Uncanny content**

> VR is an immersive medium. It creates the sensation of being entirely transported into a virtual (or real, but digitally reproduced) three-dimensional world, and it can provide a far more visceral experience than screen-based media. Enabling the mind’s continual suspension of disbelief requires particular attention to detail...  - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

The closer we get to experiences we have every day (e.g. walking), the higher the risk of creating perceptual cues that do not match reality. This may be related to the *uncanny valley*. Characters not looking at you / not responding to you properly can be particularly disturbing.

More abstract worlds are less likely to cause such conflicts; non-photorealistic environments in many ways have advantages. Overly realistic environments can also confuse immersants -- who may begin to expect that *everything* in the environment can be interacted with, and be disappointed when it isn't. 

Alternatively, let all things be interactive:

<div class="youtube" data-embed="_TPXop3ONPk"></div>

**Muscle fatigue**

> People will typically move their heads/bodies if they have to shift their gaze and hold it on a point farther than 15-20° of visual angle away from where they are currently looking. Avoid forcing the user to make such large shifts to prevent muscle fatigue and discomfort. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/) 

Keep most content at a comfortable viewing angle. It is uncomfortable to look up or down for very long, or to twist sideways frequently or for sustained time. 

> Don’t require the user to swivel their eyes in their sockets to see the UI. Ideally, your UI should fit inside the middle 1/3rd of the user’s viewing area; otherwise, they should be able to examine it with head movements. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

And if you expect people to sit through the experience, remember that they will only rarely (if at all) see things behind them.

**Experiment**

Try other ideas out. Try them out on lots of people. Just because it feels OK for you doesn't mean it will for others -- and this is more true the more time you spend in VR.

Give people the option to control the intensity of effects that can induce nausea. Not everyone wants to be limited, and some players are willing to forego comfort (or simply are less susceptible to the nausea); recent examples of succesful games that 'break the rules' in this way include Onward and Climbey.

**Learn how to avoid it**

Hardly a solution, but there are a few techniques that people susceptible to sim sickness can make use of: 

- Take time to calibrate the headset to your eyes -- your inter-pupillary distance, your field of view, the height of your eyes above ground (when standing), etc.
- When turning, keep your eyes locked on to a specific point. Also, focus on the horizon in moments that you feel unsteady.
- Close your eyes for any nausea-inducing moments.
- Sitting is usually better than standing, so long as the experience can place you at an appropriate height in the virtual world. Some prefer lying on their backs.
- Remember to take breaks.
- Don't expose yourself to nauseating experiences too often -- it can make you more sensitive, and create negative associations that are hard to shake (e.g. with the smell of the headset).
- On the other hand, over time the effect can reduce. Early pseudo-3D game such as Doom and Duke Nukem, at very low resolutions on screens, were still able to evoke motion sickness in players -- this seems remarkable and difficult to believe today -- but it suggests that perhaps VR experiences will be less nauseating the more we are used to them.

> When a land-lubber steps onto a boat for the first time, often the rocking and variations in vestibular motion from the ocean causes a feeling of ‘sea-sickness’ that is not too different from simulator sickness. However, for most people, after a few hours or days that feeling typically dissipates as they get what is commonly referred to as their ‘sea legs.’ It is something that experienced seamen are very well adapted to. It is also something, I would argue, that replicates itself in VR. - [5 ways to reduce motion sickness in VR](http://uploadvr.com/five-ways-to-reduce-motion-sickness-in-vr/) 

- Do it in a well-ventilated space, at a comfortable temperature.
- Eat ginger (a long known remedy for motion sickness). Some also recommend a little alcohol, while others say that this makes it worse. Do not try VR when sick, hungover, etc. 
> A popular household remedy in Asia is rub eucalypti leaves together and inhale the scent produced from them. - [Sim Sickness guide on Oculus forums](https://forums.oculus.com/viewtopic.php?t=170)

---

### Space and the body 

- We cannot focus on objects closer than ~5cm, for some people as much as 20cm, so it is good to avoid placing virtual content too close to the head. And in general it is disturbing for objects to intersect the body (whether a virtual body exists or not). Static objects are usually fine as most people will naturally move around them, but dynamic objects may need to be aware of where the person is.

> Converging the eyes on objects closer than the comfortable distance range above can cause the lenses of the eyes to misfocus, making clearly rendered objects appear blurry as well as lead to eyestrain. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

- Shocking/scary etc. content is much more powerful in VR, as it can approach the body and trigger physiological responses in a way that past media could not. For example, too much action of flying bullets, explosions, moving vehicles etc. around the user can be distressing, where it would be quite acceptable in a screen-based film/game. For good reason a lot of early VR experiences are in the horror genre. Compare the slow-motion time of the Showdown demo.

> When we started tinkering with the DK1 back in the beginning of 2014, the VR scene was pretty much two things: first-person view horror games and rollercoasters. A lot of people saw the future of VR entertainment as that kind of experiences. - [Locomotion and the fear of VR](http://fatedblog.com/2015/08/06/locomotion-simulation-sickness-and-the-fear-of-vr/)

- You may need to consider the physical limits of the space in which tracking works (and in which it is safe for a blind person to move around). Again, the hardware's drivers are beginning incorporate features to automatically show the tracking limits (e.g. the blue grid that becomes visible in the Vive).

> Provide the user with warnings as they approach (but well before they reach) the edges of the position camera’s tracking volume as well as feedback for how they can re-position themselves to avoid losing tracking. We recommend you do not leave the virtual environment displayed on the Rift screen if the user leaves the camera’s tracking volume, where positional tracking is disabled. It is far less discomforting to have the scene fade to black or otherwise attenuate the image (such as dropping brightness and/or contrast) before tracking is lost. - [Best practices, Oculus](https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/)

- 3D depth perception is extremely powerful at short range, and effective within a range of a few meters. Beyond 10 meters, stereopsis ceases to be the most important depth cue, and parallax (i.e. moving via position tracking), texture, size, lighting etc. take precedence. It therefore makes sense to place significant content and interaction in this range. For this reason, user interface overlays are usually positioned 1-3 meters away. Several HMDs have their optics (lenses etc.) designed to make it most comfortable to view virtual objects within a handful of meters. 

- [Beyond around 60m](https://forums.oculus.com/viewtopic.php?f=33&t=4155),  there is virtually no distinguishable stereopsis effect at all, and it can be effectively rendered in mono (may be more efficient).

- Spatializing audio is much more important -- presenting audio in mono, or worse, in a single speaker, breaks immersion. Headphone audio should also use head orientation, and located sounds should get significantly louder when you lean toward them closely. 

- Until headsets go wireless (perhaps 2017) the tethering cable to the headset can limit certain motions.

- Physical interaction devices can't been seen while wearing a headset. The keyboard in particular is almost impossible to use. 

> “In VR, you don’t have a keyboard full of hotkeys,” says Malaika. “The buttons on a controller are much more limited, so you have to think about how to provide the same number of choices…and manage the number of choices a user has.”   - [Valve advice for VR](http://www.gamasutra.com/view/news/250362/Valve_shares_advice_on_designing_great_VR_game_interactions.php)

- Even with tracked hand-held devices, or tracking via Leap Motion or the Kinect, there is still no haptic feedback -- no sense of touch. For some reason, gloves are not in fashion for VR this time around (as they were in the 90's). For Leap Motion in particular, [here are some accumulated best practices.](https://developer.leapmotion.com/assets/Leap%20Motion%20VR%20Best%20Practices%20Guidelines.pdf). There has been some research into using ultrasonic haptic displays, but the effective range is low. The state of the art in touch is to put physical objects in space:

<div class="youtube" data-embed="NSCZxsd-9hA"></div>



**See also:**

	
(Elements borrowed from [Kevin Burke's guide](https://kev.inburke.com/slides/virtual-reality/), [Simulator Sickness](http://www.gamasutra.com/blogs/BenLewisEvans/20140404/214732/Simulation_Sickness_and_VR__What_is_it_and_what_can_developers_and_players_do_to_reduce_it.php))

[Tips from a team who ported a base-jumping game to VR](https://youtu.be/DqZZKi4UHuo?list=PLckFgM6dUP2hc4iy-IdKFtqR9TeZWMPjm&t=228)

See the [Simulator Sickness questionnaire](https://www.twentymilliseconds.com/html/ssq-scoring.html)

- [Valve advice in interaction in VR](http://www.gamasutra.com/view/news/250362/Valve_shares_advice_on_designing_great_VR_game_interactions.php)

</script>
</div>
</div>
</div>
<script src="js/marked.js"></script>
<script>

var renderer = new marked.Renderer();
var toc = []; // your table of contents as a list.
renderer.heading = function(text, level) {
	var slug = text.toLowerCase().replace(/[^\w]+/g, '-');
	if (level == 2) {
		toc.push("- [" + text + "](#"+slug+")");
	}
	return "<h" + level + " id=\"" + slug + "\"><a href=\"#" + slug + "\" class=\"anchor\"></a>" + text + "</h" + level + ">";
};

var convertMarkdown = function(text) {
	toc = [];
	var body = marked(text, { renderer: renderer });
	document.getElementById('toc').innerHTML = marked(toc.join("\n"));
	return body;
};

var body = document.getElementById('sourcetext').innerText;
document.getElementById('main_body').innerHTML = convertMarkdown(body);

function addyoutube(element, id) {
	// Load the image asynchronously
    var image = new Image();
	image.src = "https://img.youtube.com/vi/"+ id +"/0.jpg";
	image.addEventListener( "load", function() { element.appendChild(image); }(i));
	
   	// click to play
    element.addEventListener( "click", function() {
    	this.innerHTML = '<iframe width="640" height="360" src="https://www.youtube.com/embed/'+id+'?rel=0" frameborder="0" allowfullscreen></iframe>';
    });
}

var youtube = document.querySelectorAll( ".youtube" );
for (var i = 0; i < youtube.length; i++) addyoutube(youtube[i], youtube[i].dataset.embed);

</script>
</body>
</html>